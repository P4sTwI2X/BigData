{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import window, hour, col\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- window: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change this parameter accordingly to your machine\n",
    "FILE_DIR = \"file:///home/p4stwi2x/Desktop/abs/taxi-data/\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"StructuredNetworkWordCount\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# main query\n",
    "\n",
    "csvSchema = StructType([StructField(\"type\", StringType(), True),\n",
    "                        StructField(\"VendorID\", IntegerType(), True),\n",
    "                        StructField(\"tpep_pickup_datetime\", TimestampType(), True),\n",
    "                        StructField(\"tpep_dropoff_datetime\",TimestampType(), True)])\n",
    "\n",
    "streamingInputDF = (\n",
    "  spark\n",
    "    .readStream\n",
    "    .schema(csvSchema)\n",
    "    # .option(\"maxFilesPerTrigger\", 1)\n",
    "    .csv(FILE_DIR)\n",
    ")\n",
    "\n",
    "streamingCountsDF = (\n",
    "  streamingInputDF\n",
    "    .groupBy(\n",
    "      window(streamingInputDF.tpep_dropoff_datetime, \"1 hour\"))\n",
    "    .count()\n",
    ")\n",
    "\n",
    "streamingCountsDF.printSchema()\n",
    "\n",
    "#main query\n",
    "query = (\n",
    "  streamingCountsDF\n",
    "    .writeStream\n",
    "    .format(\"memory\")         # console or memory(= store in-memory table)\n",
    "    .queryName(\"counts\")      # counts = name of the in-memory table\n",
    "    .outputMode(\"complete\")\n",
    "    # .option(\"truncate\", \"false\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "query.processAllAvailable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|{2015-12-01 00:00:00, 2015-12-01 01:00:00}|7396 |\n",
      "|{2015-12-01 01:00:00, 2015-12-01 02:00:00}|5780 |\n",
      "|{2015-12-01 02:00:00, 2015-12-01 03:00:00}|3605 |\n",
      "|{2015-12-01 03:00:00, 2015-12-01 04:00:00}|2426 |\n",
      "|{2015-12-01 04:00:00, 2015-12-01 05:00:00}|2505 |\n",
      "|{2015-12-01 05:00:00, 2015-12-01 06:00:00}|3858 |\n",
      "|{2015-12-01 06:00:00, 2015-12-01 07:00:00}|10258|\n",
      "|{2015-12-01 07:00:00, 2015-12-01 08:00:00}|19007|\n",
      "|{2015-12-01 08:00:00, 2015-12-01 09:00:00}|23799|\n",
      "|{2015-12-01 09:00:00, 2015-12-01 10:00:00}|24003|\n",
      "|{2015-12-01 10:00:00, 2015-12-01 11:00:00}|21179|\n",
      "|{2015-12-01 11:00:00, 2015-12-01 12:00:00}|20219|\n",
      "|{2015-12-01 12:00:00, 2015-12-01 13:00:00}|20522|\n",
      "|{2015-12-01 13:00:00, 2015-12-01 14:00:00}|20556|\n",
      "|{2015-12-01 14:00:00, 2015-12-01 15:00:00}|21712|\n",
      "|{2015-12-01 15:00:00, 2015-12-01 16:00:00}|22016|\n",
      "|{2015-12-01 16:00:00, 2015-12-01 17:00:00}|18034|\n",
      "|{2015-12-01 17:00:00, 2015-12-01 18:00:00}|19719|\n",
      "|{2015-12-01 18:00:00, 2015-12-01 19:00:00}|25563|\n",
      "|{2015-12-01 19:00:00, 2015-12-01 20:00:00}|28178|\n",
      "|{2015-12-01 20:00:00, 2015-12-01 21:00:00}|27449|\n",
      "|{2015-12-01 21:00:00, 2015-12-01 22:00:00}|27072|\n",
      "|{2015-12-01 22:00:00, 2015-12-01 23:00:00}|24078|\n",
      "|{2015-12-01 23:00:00, 2015-12-02 00:00:00}|18806|\n",
      "+------------------------------------------+-----+\n",
      "\n",
      "Query executed\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.utils\n",
    "\n",
    "try:\n",
    "    spark.sql('select * from counts order by window').show(24, truncate=False)\n",
    "    print (\"Query executed\")\n",
    "except pyspark.sql.utils.AnalysisException:\n",
    "    print(\"Unable to process your query!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp 360000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-360000\n",
      "Timestamp 720000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-720000\n",
      "Timestamp 1080000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-1080000\n",
      "Timestamp 1440000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-1440000\n",
      "Timestamp 1800000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-1800000\n",
      "Timestamp 2160000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-2160000\n",
      "Timestamp 2520000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-2520000\n",
      "Timestamp 2880000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-2880000\n",
      "Timestamp 3240000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-3240000\n",
      "Timestamp 3600000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-3600000\n",
      "Timestamp 3960000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-3960000\n",
      "Timestamp 4320000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-4320000\n",
      "Timestamp 4680000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-4680000\n",
      "Timestamp 5040000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-5040000\n",
      "Timestamp 5400000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-5400000\n",
      "Timestamp 5760000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-5760000\n",
      "Timestamp 6120000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-6120000\n",
      "Timestamp 6480000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-6480000\n",
      "Timestamp 6840000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-6840000\n",
      "Timestamp 7200000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-7200000\n",
      "Timestamp 7560000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-7560000\n",
      "Timestamp 7920000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-7920000\n",
      "Timestamp 8280000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-8280000\n",
      "Timestamp 8640000 has been exported to folder file:///home/p4stwi2x/Desktop/abs/output_task_2/output-8640000\n"
     ]
    }
   ],
   "source": [
    "# write into files\n",
    "output_path_ex02 = 'file:///home/p4stwi2x/Desktop/abs/output_task_2'\n",
    "hour_count = spark.sql('select * from counts order by window')\\\n",
    "        .withColumn(\"temp\", (hour(col('window').start) + 1) * 360000)\n",
    "for hour in hour_count.collect():\n",
    "    timestamp_count = hour['temp']\n",
    "    windows_data = hour['window']\n",
    "    windows_count = hour['count']\n",
    "    output_dir = os.path.join(output_path_ex02, f\"output-{timestamp_count}\")\n",
    "\n",
    "    df_windows = spark.createDataFrame([(windows_count,)], [\"count\"])\n",
    "\n",
    "    df_windows.write.mode(\"overwrite\")\\\n",
    "            .format(\"csv\")\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .save(output_dir)\n",
    "\n",
    "    print(f\"Timestamp {timestamp_count} has been exported to folder {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
